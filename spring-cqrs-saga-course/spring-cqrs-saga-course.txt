Event driven microservices
a. generally microservices commuicate using http request/response model
 however in case one microservice need to all n microservices and in future more service may come
	we need to do something to reduce this on to many relation ship and n netwrok calls from cleint using req/res model whihc is blocking and slow
b. we can decouple this communication using event driven architechture using kafka/rabbit mq like event broker	

saga
a . choreography based : uses mesasge broker and all microservie communicate via events -> event driven microservices
	in this individual service have code for publishing succes event as well as rollback event consumption code
b. orchestration based : also uses message broker
  however in this a seperate microservice exist whihc have undoing code for each fo the failure events
	in orchestration do ,redo and undo code is present in individual microservice but here the undo code and redo code is present on seperate microservice
	in short the orchestration service have steps of do/redo/undo at one place and can be helpful for new dev to understand the actual flow
	
	event sourcing: instead of stroing only latest state we keep track of all the state modification event is some D.B like h2 or mysql or mongo
	at any point of failure we can run through these event store to find the latest state
	it also helps in debugging as we can replay the history of events upto specfic time and see within whihc range of events defect arised
		and hence we can debug only those specific event/events and business code


so using kafka with code logic for workflow in individual service is example of choreography
but axon helps in orchestration as logic/workflow of do redo movement is present in one of the micro service/seprate service
	it can be kept in the microservice itself whihc starts the flow
		
axon server configuration documentation:
https://docs.axoniq.io/reference-guide/axon-server/administration/admin-configuration/configuration#configuration-properties		

overall flow in command apis:

message interceptor aka command interceptor is good place for command validation as it saves wrong command to be pusehd to command bus
http request -> hibernate validation -> command controller -> commandgateway dispatch -> message interceptor(another place for validation of command) command bus -> 
			-> command handler (validation of command and creation of events) -> event bus (push to event source(d.b like h2/mongo) and then to kafka for query api)
			-> event sourcing handler (update the aggregate state) -> event handler from query api picks event from event bus and update D.B
			

overall flow in query apis:
http request -> query contrller -> querygateway dispatch -> query bus(internal) -> queryhandler calls db and create object
    -> copletablefuture object is taken from query bus result
	
we can see at each level even within command and query api it is decoupled and even internal calls are async using internal bus	


-- most effective concept is that the command gateway/ command bus + event bus / event gateway , query gateway / query bus are all shared among multiple services
as these bus exist in the axon server and any microservice be it query/command or another service can take data from this bus using @commandhandler/ @evenhandler methods

//for multiple instance of same microservice this is important to put in eventhandler in query api
@ProcessingGroup("user-service-group")

---deadlines
deadline is an event that take place when there is absence of an event
eg we created a command and it should be handled and an event is to be sent, but in case there is a timeout and wihtin taht duration an event is not recieved
a deadline event can be triggerred
very useful for sagas whihc have multiple steps meaning multple commands and events and there has to be a timeout and tracking for individual events
can be used with saga or even wihout saga
deadline events are not stored in event source
deadline manager type:
a. simple deadline manager: stores deadline schedule in memory , so jvm shut downs we loose this schedule
b. quartz deadline manager: stores deadline schedule in persistent D.B so used in production

----susbscription----
- quite similar to subscription in graphql, qhere client creates a connection and for every update on data a stream of event is pushed to clietn
	once client cacnels subscription server will not send the updates 
- very useful in cqrs apis as the command executes in command api and makes the read api eventual consistent as data will get updated a bit late
		if before this update client asks query in query api then it will get stale data,
		specially in saga since multiple apis are called to get updated data , it will get stale data untill all the saga is complete
		in these case client can ask for subscription query instead of sinple query and as soon as data is recieved after all saga client will get the response
		also until client cancels the subscription it keeps on getting newer updates on that aggregate object state change
		
		-- snapshoting
		typically in cqrs application event store have all the events in it
		anytime we want to update an aggregate for better consistency axon creates fresh aggregate object and updates it based on all the events present in event store
		in case event store have less entries then not much performance issue occurs, but in case huge entries exist it can be performance bottleneck
		
		we can use snapshot to optimize performance, on every 4/n updates in event store we can have the final result in form of snapshot
		so next time to rebuild the object during aggregate object we need not to run all the events one by one, but these intermediate snapshots will be ran whihc are less and hence optimize performance
		
		snapshot runs asynchronously and can be configured to run based on interval or based on every freequency of event update colunt in event store
		
		---replayable
		in cqrs all the actions of state change of aggregate object remains persisted in event store
		and all the business logic is created to update its state in query api, in case logic have some bug or we want to enahnce feature
		
		and for same aggregate we want to run the vent from begining to find the actual new state with new bug fix/new ehancement we can do using replayable feature
		also it can help in debugging as we can replay based on specific state and here we can identity within which range of data issue existed and we can bug fix easily

it can only be used for trasn processor
steps:
a. @ResetHandler method in event handler is called(ccan also be in command api) here we can clear existing d.b so that freshly with new business logic all events are executed
b. another annotaion: using this we can skip specific methods, like email sending/notification as we are replaying to fix issues on our side and hence we do not want the method to execute during replay		
		